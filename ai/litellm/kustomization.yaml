apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
namespace: litellm
resources: []
  # - manifests/db.yaml
configMapGenerator:
- envs:
  - manifests/configs/env.conf
  name: litellm-env
secretGenerator:
- envs:
  - manifests/secrets/env.secret.conf
  name: litellm-env
  type: Opaque

  # options:
  #   disableNameSuffixHash: true

helmCharts:
- name: litellm-helm
  releaseName: litellm
  namespace: litellm
  version: 0.1.730
  repo: oci://ghcr.io/berriai/
  valuesInline:

    masterkeySecretName: "litellm-env"
    masterkeySecretKey: "LITELLM_MASTER_KEY"

    replicaCount: 1
    environmentSecrets:
      - litellm-env
    environmentConfigMaps:
      - litellm-env
    ingress:
      enabled: true
      annotations:
        cert-manager.io/cluster-issuer: letsencrypt-prod
        # nginx.ingress.kubernetes.io/auth-signin:  'https://oauth2-proxy.kubespray.com/oauth2/start?rd=https%3A%2F%2F$host$escaped_request_uri'
        # nginx.ingress.kubernetes.io/auth-url: 'http://oauth2-proxy.dex.svc.cluster.local/oauth2/auth'
      hosts:
        - host: litellm.micros.io
          paths:
            - path: /
              pathType: Prefix
      tls:
        - secretName: litellm-certs
          hosts:
            - litellm.micros.io
    proxy_config:

      model_list:
        - model_name: fake-openai-endpoint
          litellm_params:
            model: openai/fake
            api_key: fake-key
            api_base: https://exampleopenaiendpoint-production.up.lza.ai
      general_settings:

        store_model_in_db: true
        store_prompts_in_spend_logs: false

      litellm_settings:
        # Logging/Callback settings
        success_callback: ["langfuse"]  # list of success callbacks
        # failure_callback: ["sentry"]  # list of failure callbacks
        request_timeout: 6000
        # callbacks: ["otel"]  # list of callbacks - runs on success and failure
        # service_callbacks: ["datadog", "prometheus"]  # logs redis, postgres failures on datadog, prometheus
        turn_off_message_logging: true
        redact_user_api_key_info: false
        langfuse_default_tags: ["cache_hit", "cache_key", "proxy_base_url", "user_api_key_alias", "user_api_key_user_email", "user_api_key_team_alias", "semantic-similarity"]
        # cache: true


    db:
      useExisting: true
      deployStandalone: false
      database: litellm
      endpoint: litellm.pg-infra.svc.cluster.local
      secret:
        name: litellm.litellm.litellm.pg.creds
        usernameKey: username
        passwordKey: password
    redis:
      enabled: true
      architecture: standalone
patches:
  - target:
      kind: StatefulSet
      name: litellm-redis-master
    patch: |
      - op: add
        path: /spec/volumeClaimTemplates/0/spec/storageClassName
        value: local

# images:
#   - name: ghcr.io/berriai/litellm-database
#     newTag: main-v1.74.4-nightly
